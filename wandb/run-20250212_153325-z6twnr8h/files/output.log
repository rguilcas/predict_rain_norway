GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

/felles_gfi/felles_gfi_users/rogui7909/miniforge3/envs/robin/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name  | Type       | Params | Mode
---------------------------------------------
0 | model | Sequential | 525 K  | train
---------------------------------------------
525 K     Trainable params
0         Non-trainable params
525 K     Total params
2.100     Total estimated model params size (MB)
4         Modules in train mode
0         Modules in eval mode
Epoch 9: 100%|█████████████████████████████████████████████████████████████████| 49/49 [00:10<00:00,  4.73it/s, v_num=nr8h]
`Trainer.fit` stopped: `max_epochs=10` reached.
